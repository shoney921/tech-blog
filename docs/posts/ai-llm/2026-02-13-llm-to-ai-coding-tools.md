---
title: "개발 복귀자를 위한 AI 총정리 - LLM부터 에이전트, 그리고 AI 코딩 도구까지"
date: 2026-02-13T12:00:00
---

# 개발 복귀자를 위한 AI 총정리

**LLM부터 에이전트, LangChain, 그리고 Cursor·Claude Code까지**

> "한동안 개발을 안 했는데, 세상이 너무 바뀌었다..."

요즘 개발 뉴스를 열면 LLM, 에이전트, RAG, LangChain, Cursor, Claude Code... 처음 보는 단어들이 쏟아진다. 마치 오랜만에 고향에 돌아왔더니 동네가 완전히 재개발된 느낌이랄까.

이 글은 **개발을 오랫동안 쉬었다가 돌아온 사람**을 위해, 최근 AI 기술의 핵심 개념을 **처음부터 차근차근**, 하나의 흐름으로 설명한다. 각 개념이 왜 나왔고, 어떻게 연결되는지를 이해하면 나머지는 금방 따라잡을 수 있다.

---

## 1장. LLM — 모든 것의 시작

### "엄청나게 똑똑한 앵무새"

**LLM(Large Language Model, 대규모 언어 모델)**은 방대한 텍스트 데이터를 학습해서 인간처럼 글을 읽고, 쓰고, 대화할 수 있는 AI 모델이다.

대표적인 LLM:
- **GPT-4** (OpenAI)
- **Claude** (Anthropic)
- **Gemini** (Google)
- **LLaMA** (Meta, 오픈소스)

쉽게 비유하면 이렇다:

```
전통적인 프로그래밍:
  입력 → [규칙을 코드로 작성] → 출력
  "if 고객등급 == 'VIP' then 할인율 = 20%"

LLM:
  입력 (자연어) → [학습된 패턴으로 추론] → 출력 (자연어)
  "VIP 고객 할인 정책 만들어줘" → "VIP 등급 고객에게 20% 할인을..."
```

핵심은 **코드 대신 말로 지시**할 수 있다는 것이다. 이것만으로도 혁명적인 변화다.

### LLM은 어떻게 작동하나?

복잡한 수학은 건너뛰고, 핵심만 짚자.

LLM은 본질적으로 **"다음에 올 단어를 예측하는 기계"**다.

```
입력: "오늘 날씨가 정말"
LLM이 하는 일: 다음 단어 확률 계산
  → "좋다" (45%)
  → "덥다" (20%)
  → "춥다" (15%)
  → ...
```

이 단순한 원리를 **수천억 개의 파라미터**와 **인터넷 규모의 데이터**로 확장하면, 놀랍게도 코딩, 번역, 분석, 창작까지 할 수 있게 된다. 마치 레고 블록 하나하나는 단순하지만, 수만 개를 조합하면 정교한 건축물이 되는 것과 같다.

### LLM의 한계 — 뭘 못하나?

LLM이 만능처럼 보이지만, 치명적인 한계가 있다:

| 한계 | 설명 | 비유 |
|------|------|------|
| **할루시네이션** | 모르는 것도 그럴듯하게 지어냄 | 시험에서 모르는 문제도 자신있게 적는 학생 |
| **지식 단절** | 학습 데이터 이후 정보를 모름 | 2024년까지 공부하고 2026년 뉴스를 모르는 사람 |
| **실행 불가** | 말만 하지, 직접 행동하지 못함 | 레시피는 알려주지만 요리는 못 하는 셰프 |
| **컨텍스트 제한** | 한 번에 처리할 수 있는 텍스트 양에 한계 | 1000페이지 책을 한 번에 다 읽지 못함 |

이 한계들을 극복하기 위해 등장한 것이 바로 **프롬프트 엔지니어링**, **RAG**, 그리고 **에이전트**다.

---

## 2장. 프롬프트 엔지니어링 — LLM과 대화하는 기술

### "같은 질문도 어떻게 하느냐에 따라 답이 달라진다"

**프롬프트(Prompt)**는 LLM에게 주는 입력 텍스트다. 그리고 **프롬프트 엔지니어링**은 원하는 결과를 얻기 위해 프롬프트를 잘 설계하는 기술이다.

```
❌ 나쁜 프롬프트:
"코드 짜줘"

✅ 좋은 프롬프트:
"Python으로 CSV 파일을 읽어서 날짜별로 매출 합계를 구하는 함수를 작성해줘.
 - pandas 사용
 - 입력: 파일 경로 (str)
 - 출력: DataFrame (날짜, 매출합계 컬럼)
 - 에러 처리 포함"
```

### 주요 프롬프트 기법들

**1. 역할 부여 (Role Prompting)**
```
"너는 10년 경력의 백엔드 개발자야.
 주니어 개발자가 이해할 수 있도록 설명해줘."
```

**2. Few-shot 예시 제공**
```
"아래 형식으로 변환해줘:

입력: 2024-01-15 → 출력: 1월 15일 (월)
입력: 2024-03-20 → 출력: 3월 20일 (수)
입력: 2024-12-25 → ?"
```

**3. 단계별 사고 유도 (Chain of Thought)**
```
"이 버그의 원인을 찾아줘.
 단계별로 생각해보자:
 1) 에러 메시지 분석
 2) 관련 코드 확인
 3) 가능한 원인 나열
 4) 가장 가능성 높은 원인 선택"
```

프롬프트 엔지니어링은 LLM을 잘 쓰기 위한 **첫 번째 도구**다. 하지만 프롬프트만으로는 LLM의 근본적 한계(실시간 정보 부족, 실행 불가)를 해결할 수 없다.

---

## 3장. RAG — LLM에게 참고서를 쥐여주다

### "시험 볼 때 오픈북 허용"

LLM은 학습 이후의 정보를 모르고, 회사 내부 문서 같은 비공개 데이터도 모른다. 이 문제를 해결하는 것이 **RAG(Retrieval-Augmented Generation, 검색 증강 생성)**이다.

원리는 놀라울 정도로 단순하다:

```
일반 LLM:
  질문 → LLM → 답변 (학습 데이터에서만)

RAG:
  질문 → [관련 문서 검색] → 질문 + 검색 결과 → LLM → 답변
```

학생에 비유하면:
- **일반 LLM** = 교과서 안 보고 시험 보는 학생 (암기에 의존)
- **RAG** = 교과서 펼쳐놓고 시험 보는 학생 (참고자료 활용)

### RAG의 실제 동작

```
[1단계: 인덱싱 - 미리 준비]
  회사 문서 1000개
    → 작은 조각(청크)으로 분할
    → 각 조각을 벡터(숫자 배열)로 변환
    → 벡터 데이터베이스에 저장

[2단계: 검색 - 질문이 들어올 때]
  "우리 회사 연차 정책이 뭐야?"
    → 질문도 벡터로 변환
    → 벡터 DB에서 가장 비슷한 문서 조각 검색
    → "연차 규정.pdf의 3페이지" 발견

[3단계: 생성 - 답변 만들기]
  질문 + 검색된 문서 조각 → LLM → 정확한 답변
```

RAG 덕분에 LLM은 **최신 정보**와 **사내 문서**까지 활용할 수 있게 되었다. ChatGPT의 웹 검색 기능, 회사 내부 챗봇 등이 모두 RAG 기반이다.

::: tip
RAG에 대해 더 깊이 알고 싶다면 이전 포스트 [RAG vs Graph RAG](/posts/ai-llm/2026-02-13-rag-vs-graph-rag)를 참고하자.
:::

---

## 4장. AI 에이전트 — LLM에 손발을 달다

### "말만 하던 AI가 직접 행동하기 시작했다"

여기서부터가 진짜 재미있는 부분이다.

기존 LLM은 아무리 똑똑해도 **말만 할 수 있었다**. "이메일을 보내야 합니다"라고 말은 하지만, 실제로 이메일을 보내지는 못했다. 마치 내비게이션이 길은 알려주지만 운전은 못하는 것처럼.

**AI 에이전트(Agent)**는 LLM에게 **도구(Tool)**를 쥐여줘서 직접 행동할 수 있게 만든 것이다.

```
일반 LLM:
  "파일을 읽어서 버그를 찾아야 합니다" (말만 함)

AI 에이전트:
  1. 파일 읽기 도구로 코드를 읽음 (행동)
  2. 버그를 분석함 (사고)
  3. 코드 수정 도구로 고침 (행동)
  4. 테스트 실행 도구로 확인함 (행동)
  5. "버그를 수정했습니다" (보고)
```

### 에이전트의 핵심 구조

에이전트는 **세 가지 요소**로 구성된다:

```
┌─────────────────────────────────────────────────┐
│                   AI 에이전트                      │
│                                                   │
│  ┌───────────┐                                    │
│  │   🧠 LLM  │  ← 두뇌: 판단하고 계획을 세움        │
│  └─────┬─────┘                                    │
│        │                                          │
│  ┌─────▼─────┐                                    │
│  │  도구 모음  │  ← 손발: 실제 작업을 수행            │
│  │           │                                    │
│  │ - 파일 읽기/쓰기                                 │
│  │ - 웹 검색                                       │
│  │ - 코드 실행                                     │
│  │ - API 호출                                      │
│  │ - DB 쿼리                                       │
│  └─────┬─────┘                                    │
│        │                                          │
│  ┌─────▼─────┐                                    │
│  │   메모리   │  ← 기억: 이전 작업 결과를 기억        │
│  └───────────┘                                    │
└─────────────────────────────────────────────────┘
```

### 에이전트의 작동 방식 — ReAct 패턴

대부분의 에이전트는 **ReAct(Reasoning + Acting)** 패턴으로 동작한다:

```
사용자: "서울의 오늘 날씨를 알려주고, 비가 오면 실내 데이트 코스를 추천해줘"

에이전트 내부 동작:

[Thought] 날씨를 먼저 확인해야 한다
[Action] 날씨 API 호출 → 서울 날씨 조회
[Observation] 서울: 비, 기온 12도

[Thought] 비가 오니까 실내 데이트 코스를 추천해야 한다
[Action] 검색 도구 → "서울 실내 데이트 코스 추천"
[Observation] 검색 결과: 미술관, 방탈출카페, 실내 클라이밍...

[Thought] 결과를 정리해서 답변하자
[Answer] "오늘 서울은 비가 오고 12도입니다.
         추천 실내 데이트 코스:
         1. 국립현대미술관 서울관
         2. 방탈출 카페
         3. ..."
```

**생각(Thought) → 행동(Action) → 관찰(Observation)**을 반복하면서, 마치 사람처럼 문제를 단계적으로 풀어나간다.

### 에이전트 vs 일반 LLM 정리

| 구분 | 일반 LLM | AI 에이전트 |
|------|----------|------------|
| 할 수 있는 것 | 텍스트 생성만 | 텍스트 생성 + 도구 사용 |
| 외부 정보 | 학습 데이터만 | 실시간 검색, API 호출 가능 |
| 코드 실행 | 불가 | 가능 |
| 다단계 작업 | 한 번에 답변 | 계획 → 실행 → 확인 반복 |
| 비유 | 상담사 (조언만) | 비서 (직접 처리) |

---

## 5장. LangChain — 에이전트를 조립하는 레고 세트

### "에이전트를 처음부터 만들 필요 없다"

AI 에이전트를 만들려면 LLM 연결, 도구 관리, 메모리 구현, 실행 흐름 제어 등 할 일이 많다. **LangChain**은 이런 것들을 **미리 만들어둔 프레임워크**다.

레고에 비유하면:
- LLM을 직접 다루기 = 레고 블록을 **직접 깎아서** 만들기
- LangChain 사용 = **레고 세트** 사서 설명서대로 조립하기

### LangChain의 핵심 개념

```
┌─────────────────────────────────────────────────────┐
│                    LangChain 생태계                    │
│                                                       │
│  ┌─────────────────────────────────────────────────┐  │
│  │ LangChain Core - 기본 추상화 레이어               │  │
│  │                                                   │  │
│  │  Model I/O    : LLM과 통신 (OpenAI, Claude 등)    │  │
│  │  Prompts      : 프롬프트 템플릿 관리               │  │
│  │  Output Parser : LLM 출력 구조화                   │  │
│  └─────────────────────────────────────────────────┘  │
│                                                       │
│  ┌─────────────────────────────────────────────────┐  │
│  │ Chains & Agents - 실행 흐름 제어                   │  │
│  │                                                   │  │
│  │  Chain : 여러 단계를 순서대로 실행                   │  │
│  │  Agent : LLM이 판단해서 도구를 선택 & 실행           │  │
│  └─────────────────────────────────────────────────┘  │
│                                                       │
│  ┌─────────────────────────────────────────────────┐  │
│  │ LangSmith - 모니터링 & 디버깅                      │  │
│  │ LangGraph - 복잡한 멀티 에이전트 워크플로우           │  │
│  │ LangServe - API 서버로 배포                        │  │
│  └─────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────┘
```

### 간단한 예시로 이해하기

LangChain으로 "문서 기반 QA 챗봇"을 만드는 과정:

```python
# 1. 문서를 로드하고 청크로 분할
from langchain_community.document_loaders import PDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

docs = PDFLoader("company_manual.pdf").load()
chunks = RecursiveCharacterTextSplitter(chunk_size=1000).split_documents(docs)

# 2. 벡터 DB에 저장 (RAG의 인덱싱)
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(chunks, OpenAIEmbeddings())

# 3. RAG 체인 구성
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4"),
    retriever=vectorstore.as_retriever(),
)

# 4. 질문하기
answer = qa_chain.invoke("우리 회사 연차 정책이 뭐야?")
```

코드 몇 줄로 **RAG 기반 QA 시스템**이 완성된다. LangChain이 LLM 호출, 벡터 검색, 프롬프트 구성 등을 알아서 처리해준다.

### LangChain 말고 다른 선택지는?

LangChain이 가장 유명하지만, 대안도 있다:

| 프레임워크 | 특징 |
|-----------|------|
| **LangChain** | 가장 큰 생태계, 풍부한 통합 |
| **LlamaIndex** | 데이터 인덱싱과 RAG에 특화 |
| **CrewAI** | 멀티 에이전트 협업에 특화 |
| **Anthropic Agent SDK** | Claude 기반 에이전트 개발 공식 SDK |
| **OpenAI Agents SDK** | OpenAI 기반 에이전트 개발 공식 SDK |

::: info
최근에는 LLM 제공사들이 자체 Agent SDK를 제공하는 추세다. 프레임워크 선택보다 **어떤 문제를 풀 것인가**가 더 중요하다.
:::

---

## 6장. AI 코딩 도구 — 개발자의 일상이 바뀌다

여기까지 읽었다면, LLM → 에이전트로 이어지는 흐름을 이해한 것이다. 이제 이 기술이 **개발자의 일상**에 어떻게 적용되는지 보자.

AI 코딩 도구는 크게 **두 가지 방식**으로 나뉜다:

```
┌──────────────────────────────────────────────────────────┐
│                    AI 코딩 도구의 두 갈래                    │
│                                                            │
│  [1] IDE 통합형 - 에디터 안에서 AI가 도와줌                    │
│      └─ Cursor, GitHub Copilot, Windsurf                   │
│         "코딩하다가 바로 AI한테 물어보고, 제안받고, 수정하고"     │
│                                                            │
│  [2] CLI/터미널형 - 터미널에서 AI가 직접 코딩                  │
│      └─ Claude Code, Codex CLI, Aider                      │
│         "AI한테 말로 시키면 알아서 파일 찾고, 코드 짜고, 커밋"   │
│                                                            │
└──────────────────────────────────────────────────────────┘
```

---

### 6-1. Cursor — AI가 내장된 코드 에디터

**Cursor**는 VS Code를 기반으로 만든 **AI 네이티브 코드 에디터**다. VS Code의 모든 기능을 그대로 쓸 수 있으면서, AI 기능이 깊이 통합되어 있다.

#### Cursor의 핵심 기능

**1. Tab 자동완성 — 코드를 미리 읽는 AI**

타이핑하는 도중에 AI가 다음에 쓸 코드를 예측해서 보여준다. GitHub Copilot과 비슷하지만, 단순한 한 줄 완성이 아니라 **여러 줄의 맥락을 파악한 제안**을 한다.

```
내가 타이핑:  function calculateTax(
Cursor 제안:  function calculateTax(income: number, rate: number): number {
                return income * rate;
              }
Tab 누르면 → 제안 수락
```

**2. Cmd+K — 코드 인라인 편집**

코드를 선택하고 `Cmd+K`를 누르면, 자연어로 수정을 요청할 수 있다.

```
[코드 선택 후 Cmd+K]
"이 함수에 에러 처리를 추가해줘"
→ AI가 try-catch를 추가한 수정 코드를 diff 형태로 보여줌
→ 수락/거절 선택
```

**3. Chat — 프로젝트를 이해하는 AI 대화**

Cursor의 채팅은 **프로젝트 전체 코드베이스를 이해**한다. `@파일명`이나 `@폴더명`으로 특정 코드를 참조하면서 대화할 수 있다.

```
나: "@src/api/auth.ts 이 인증 로직에서 토큰 만료 처리가
     제대로 되고 있는지 확인해줘"

Cursor: "auth.ts를 분석한 결과, refreshToken 호출 시
         경쟁 조건(race condition) 문제가 있습니다.
         여러 요청이 동시에 토큰 갱신을 시도할 수 있어요.
         다음과 같이 수정을 제안합니다..."
```

**4. Agent 모드 — 알아서 다 해주는 모드**

가장 강력한 기능이다. Cursor에게 작업을 맡기면 **파일을 찾고, 코드를 수정하고, 터미널 명령을 실행**하는 것까지 자동으로 한다.

```
나: "로그인 API에 rate limiting을 추가해줘"

Cursor Agent:
  1. 프로젝트 구조 파악
  2. 관련 파일 탐색 (auth.controller.ts, middleware/ 등)
  3. rate limiter 미들웨어 생성
  4. 라우터에 미들웨어 적용
  5. 필요한 패키지 설치 (npm install express-rate-limit)
  6. 변경 사항 요약
```

#### Cursor를 한마디로?

> **"AI가 내 코드를 이해하는 VS Code"** — 기존 에디터 경험을 유지하면서 AI의 도움을 자연스럽게 받을 수 있다.

---

### 6-2. Claude Code — 터미널에서 일하는 AI 개발자

**Claude Code**는 Anthropic이 만든 **CLI 기반 AI 코딩 에이전트**다. 에디터가 아니라 **터미널**에서 동작하며, 자연어로 지시하면 AI가 알아서 코드를 읽고, 수정하고, 실행한다.

#### 왜 CLI인가?

IDE 안의 AI와 CLI AI는 작업 방식이 근본적으로 다르다:

```
Cursor (IDE 통합형):
  나: [코드를 보면서] "이 부분 수정해줘" → AI가 수정 제안 → 내가 확인

Claude Code (CLI형):
  나: "인증 버그 고쳐줘" → AI가 알아서 파일 탐색 → 원인 분석 →
  코드 수정 → 테스트 실행 → "고쳤습니다, 이렇게 수정했어요"
```

Cursor가 **페어 프로그래밍 파트너**라면, Claude Code는 **독립적으로 일하는 팀원**에 가깝다.

#### Claude Code의 핵심 기능

**1. 자연어로 코딩**

```bash
$ claude
> 이 프로젝트의 구조를 파악하고 README를 업데이트해줘

Claude Code:
  [파일 트리 탐색 중...]
  [package.json 읽는 중...]
  [src/ 디렉토리 분석 중...]
  [README.md 수정 중...]

  프로젝트를 분석하고 README를 업데이트했습니다:
  - 프로젝트 구조 섹션 추가
  - 설치 방법 업데이트
  - API 엔드포인트 목록 추가
```

**2. 코드베이스 전체를 이해**

Claude Code는 프로젝트의 파일을 직접 읽고 탐색한다. "이 프로젝트에서 인증은 어떻게 처리돼?" 같은 질문에도 실제 코드를 찾아서 답한다.

**3. Git 워크플로우 통합**

```bash
> 지금까지 작업한 내용을 커밋하고, PR을 만들어줘

Claude Code:
  [변경 사항 확인 중...]
  [커밋 메시지 작성 중...]
  [git commit 실행...]
  [PR 생성 중...]

  PR #42를 생성했습니다: "feat: add rate limiting to auth endpoints"
```

**4. 멀티 파일 리팩토링**

```bash
> 프로젝트 전체에서 moment.js를 dayjs로 교체해줘

Claude Code:
  [moment.js 사용처 검색 중... 23개 파일 발견]
  [의존성 분석 중...]
  [파일별 마이그레이션 수행 중...]
  [테스트 실행으로 확인 중...]

  23개 파일에서 moment.js를 dayjs로 교체했습니다.
  모든 테스트가 통과합니다.
```

#### Claude Code를 한마디로?

> **"터미널에서 일하는 AI 팀원"** — 지시하면 알아서 코드를 탐색하고, 수정하고, 테스트까지 돌린다.

---

### 6-3. Cursor vs Claude Code — 뭘 써야 할까?

이 둘은 경쟁이 아니라 **다른 상황에서 빛나는 도구**다:

| 상황 | 추천 도구 | 이유 |
|------|----------|------|
| 코드를 보면서 수정할 때 | **Cursor** | 시각적 피드백, diff 확인 용이 |
| 큰 리팩토링을 맡길 때 | **Claude Code** | 자동으로 여러 파일 탐색 & 수정 |
| 새 기능 프로토타이핑 | **Cursor** | 빠른 반복, 즉시 확인 |
| 버그 원인 찾기 | **둘 다** | Cursor는 대화형, Claude Code는 자동 탐색 |
| CI/CD 파이프라인에서 | **Claude Code** | CLI 기반이라 자동화에 적합 |
| 코드 리뷰 & PR 작성 | **Claude Code** | Git 통합이 강력 |

::: tip 실전 조합
많은 개발자가 **Cursor로 코딩하면서, Claude Code로 큰 작업을 맡기는** 방식으로 두 도구를 함께 사용한다. 에디터에서는 Cursor, 터미널에서는 Claude Code — 이것이 2026년의 개발 워크플로우다.
:::

---

## 7장. 전체 그림 — 모든 개념의 연결

지금까지 다룬 내용을 하나의 그림으로 정리하자:

```
[기반 기술]
  LLM (GPT, Claude, Gemini...)
   │
   ├─ 프롬프트 엔지니어링 → LLM을 잘 쓰는 기술
   │
   ├─ RAG → LLM + 외부 지식 검색
   │
   └─ AI 에이전트 → LLM + 도구 사용 + 자율 판단
       │
       ├─ 프레임워크: LangChain, LlamaIndex, Agent SDK...
       │   → 에이전트를 쉽게 만드는 도구
       │
       └─ 코딩 도구: 에이전트 기술의 실제 적용
           ├─ Cursor → IDE 안의 AI 코딩 파트너
           └─ Claude Code → 터미널의 AI 코딩 에이전트
```

각 개념이 앞의 개념 위에 쌓여있다는 걸 알 수 있다:
1. **LLM**이 있으니까 → 자연어로 소통 가능
2. **프롬프트 엔지니어링**으로 → LLM을 더 잘 활용
3. **RAG**로 → LLM의 지식 한계를 극복
4. **에이전트**로 → LLM이 직접 행동 가능
5. **LangChain** 같은 프레임워크로 → 에이전트를 쉽게 제작
6. **Cursor, Claude Code**로 → 개발자의 일상에 AI가 들어옴

---

## 마무리 — 어디서부터 시작할까?

개발에 복귀했다면, 다음 순서를 추천한다:

**1단계: AI 코딩 도구부터 써보자**
- Cursor를 설치하고 평소처럼 코딩하면서 AI 제안을 받아보자
- Claude Code를 터미널에서 써보면서 자연어로 코딩하는 경험을 해보자
- 이 단계에서 LLM의 가능성을 직접 체감하게 된다

**2단계: 프롬프트 엔지니어링을 익히자**
- AI에게 더 정확한 결과를 얻기 위해 프롬프트를 다듬어보자
- 역할 부여, 예시 제공, 단계적 사고 유도 등을 연습하자

**3단계: RAG와 에이전트 개념을 이해하자**
- AI 코딩 도구가 내부적으로 어떻게 작동하는지 이해하게 된다
- 필요하다면 LangChain으로 간단한 프로젝트를 만들어보자

핵심은 **이론보다 실습이 먼저**라는 것이다. AI 코딩 도구를 써보면 "아, LLM이 이런 거구나"를 자연스럽게 체감하게 되고, 나머지 개념들도 물 흐르듯 이해가 된다.

개발의 본질은 변하지 않았다. **문제를 정의하고, 해결 방법을 설계하고, 코드로 구현하는 것.** 다만 이제는 그 과정에서 AI라는 강력한 도구가 옆에 있을 뿐이다.

---

## 참고 자료

- [Anthropic - Claude Code](https://docs.anthropic.com/en/docs/claude-code)
- [Cursor - The AI Code Editor](https://www.cursor.com/)
- [LangChain 공식 문서](https://python.langchain.com/)
- [LangChain - What is an Agent?](https://python.langchain.com/docs/concepts/agents/)
- [ReAct: Synergizing Reasoning and Acting in Language Models (arxiv, 2022)](https://arxiv.org/abs/2210.03629)
- [Anthropic - Building effective agents](https://www.anthropic.com/research/building-effective-agents)
- [OpenAI - A Practical Guide to Building Agents](https://platform.openai.com/docs/guides/agents)
