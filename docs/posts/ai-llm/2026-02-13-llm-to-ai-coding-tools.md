---
title: "개발 복귀자를 위한 AI 이야기 — LLM부터 에이전트, AI 코딩 도구까지"
description: LLM, 에이전트, RAG, LangChain, Cursor, Claude Code 등 최근 AI 기술의 핵심 개념을 처음부터 풀어본다.
date: 2026-02-13T12:00:00
---

# 개발 복귀자를 위한 AI 이야기

> "한동안 개발을 안 했는데, 세상이 너무 바뀌었다..."

요즘 개발 뉴스를 열면 LLM, 에이전트, RAG, LangChain, Cursor, Claude Code... 처음 보는 단어들이 쏟아진다. 마치 오랜만에 고향에 돌아왔더니 동네가 완전히 재개발된 느낌이랄까.

이 글은 개발을 오랫동안 쉬었다가 돌아온 사람을 위해, 최근 AI 기술의 핵심 개념을 하나의 흐름으로 풀어본다. 각 개념이 왜 나왔고 어떻게 연결되는지를 이해하면 나머지는 금방 따라잡을 수 있다.

---

## LLM — 모든 것의 시작

LLM(Large Language Model)은 방대한 텍스트 데이터를 학습해서 사람처럼 글을 읽고 쓰고 대화할 수 있는 AI 모델이다. GPT-4, Claude, Gemini, LLaMA 같은 이름을 들어봤을 텐데, 다 LLM이다.

전통적인 프로그래밍은 `if 고객등급 == 'VIP' then 할인율 = 20%` 같은 규칙을 코드로 작성했다면, LLM은 "VIP 고객 할인 정책 만들어줘"라고 말로 지시할 수 있다. 이것만으로도 꽤 혁명적인 변화다.

LLM의 작동 원리를 극도로 단순화하면, "다음에 올 단어를 예측하는 기계"다. "오늘 날씨가 정말"이라는 입력이 들어오면 "좋다"(45%), "덥다"(20%), "춥다"(15%)... 식으로 확률을 계산한다. 이 단순한 원리를 수천억 개의 파라미터와 인터넷 규모의 데이터로 확장하면, 놀랍게도 코딩, 번역, 분석, 창작까지 가능해진다.

하지만 LLM에도 치명적인 한계가 있다. 모르는 것도 자신있게 지어내는 할루시네이션, 학습 데이터 이후 정보를 모르는 지식 단절, 말만 하고 직접 행동하지 못하는 점, 한 번에 처리할 수 있는 텍스트 양에 한계가 있는 컨텍스트 제한. 이 한계들을 극복하기 위해 등장한 게 프롬프트 엔지니어링, RAG, 그리고 에이전트다.

---

## 프롬프트 엔지니어링 — 같은 질문도 어떻게 하느냐에 따라 다르다

프롬프트는 LLM에게 주는 입력 텍스트다. 그리고 프롬프트 엔지니어링은 원하는 결과를 얻기 위해 프롬프트를 잘 설계하는 기술이다.

"코드 짜줘"와 "Python으로 CSV 파일을 읽어서 날짜별 매출 합계를 구하는 함수를 작성해줘. pandas 사용, 에러 처리 포함"은 결과가 완전히 다르다. 역할 부여("너는 10년 경력 백엔드 개발자야"), Few-shot 예시 제공, Chain-of-Thought("단계별로 생각해보자") 같은 기법들이 있는데, 별것 아닌 것 같지만 결과 차이가 생각보다 크다.

처음에 나도 "그냥 말하면 되는 거 아냐?"라고 생각했는데, 프롬프트를 조금 다듬는 것만으로 훨씬 정확한 결과를 얻을 수 있었다. 다만 프롬프트만으로는 LLM의 근본적 한계(실시간 정보 부족, 실행 불가)를 해결할 수 없다.

---

## RAG — LLM에게 참고서를 쥐여주다

LLM은 학습 이후의 정보를 모르고, 회사 내부 문서 같은 비공개 데이터도 모른다. RAG(Retrieval-Augmented Generation)는 이 문제를 해결한다.

원리는 놀라울 정도로 단순하다. 일반 LLM이 "교과서 안 보고 시험 보는 학생"이라면, RAG는 "교과서 펼쳐놓고 시험 보는 학생"이다.

```
일반 LLM:  질문 → LLM → 답변 (학습 데이터에서만)
RAG:      질문 → [관련 문서 검색] → 질문 + 검색 결과 → LLM → 답변
```

실제로는 회사 문서를 작은 조각(청크)으로 분할하고, 각 조각을 벡터로 변환해서 벡터 DB에 저장한다. 질문이 들어오면 질문도 벡터로 변환한 뒤 가장 비슷한 문서 조각을 검색하고, 그걸 LLM에게 맥락으로 전달한다. ChatGPT의 웹 검색 기능, 회사 내부 챗봇 등이 다 RAG 기반이다.

---

## AI 에이전트 — LLM에 손발을 달다

여기서부터가 진짜 재미있는 부분이다.

기존 LLM은 아무리 똑똑해도 말만 할 수 있었다. "이메일을 보내야 합니다"라고 말은 하지만, 실제로 이메일을 보내지는 못했다. AI 에이전트는 LLM에게 도구(Tool)를 쥐여줘서 직접 행동할 수 있게 만든 것이다.

```
일반 LLM:
  "파일을 읽어서 버그를 찾아야 합니다" (말만 함)

AI 에이전트:
  1. 파일 읽기 도구로 코드를 읽음
  2. 버그를 분석함
  3. 코드 수정 도구로 고침
  4. 테스트 실행 도구로 확인함
  5. "버그를 수정했습니다"
```

에이전트는 크게 세 가지로 구성된다. 판단하고 계획을 세우는 LLM(두뇌), 실제 작업을 수행하는 도구 모음(손발), 이전 작업 결과를 기억하는 메모리. 대부분 ReAct(Reasoning + Acting) 패턴으로 동작하는데, 생각(Thought) → 행동(Action) → 관찰(Observation)을 반복하면서 문제를 단계적으로 풀어나간다.

---

## LangChain — 에이전트를 만드는 프레임워크

에이전트를 처음부터 만들면 할 일이 많다. LLM 연결, 도구 관리, 메모리 구현, 실행 흐름 제어... LangChain은 이런 걸 미리 만들어둔 프레임워크다.

LangChain으로 문서 기반 QA 챗봇을 만드는 코드를 보면 감이 온다.

```python
# 1. 문서 로드 & 청크 분할
docs = PDFLoader("company_manual.pdf").load()
chunks = RecursiveCharacterTextSplitter(chunk_size=1000).split_documents(docs)

# 2. 벡터 DB에 저장
vectorstore = Chroma.from_documents(chunks, OpenAIEmbeddings())

# 3. RAG 체인 구성
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4"),
    retriever=vectorstore.as_retriever(),
)

# 4. 질문
answer = qa_chain.invoke("우리 회사 연차 정책이 뭐야?")
```

코드 몇 줄로 RAG 기반 QA 시스템이 만들어진다. LangChain 말고도 LlamaIndex(RAG 특화), CrewAI(멀티 에이전트), Anthropic Agent SDK, OpenAI Agents SDK 같은 대안들이 있다. 최근에는 LLM 제공사들이 자체 SDK를 제공하는 추세여서, 프레임워크 선택보다 어떤 문제를 풀 것인가가 더 중요하다고 느낀다.

---

## AI 코딩 도구 — 개발자의 일상이 바뀌다

LLM에서 에이전트로 이어지는 흐름을 이해했다면, 이 기술이 개발자의 일상에 어떻게 들어왔는지 보자. AI 코딩 도구는 크게 두 갈래다.

**IDE 통합형** — Cursor, GitHub Copilot, Windsurf 같은 도구로, 에디터 안에서 AI가 도와준다. 코딩하다가 바로 AI한테 물어보고, 제안받고, 수정하는 방식이다.

**CLI/터미널형** — Claude Code, Codex CLI, Aider 같은 도구로, 터미널에서 AI가 직접 코딩한다. 자연어로 시키면 알아서 파일 찾고, 코드 짜고, 테스트 돌린다.

### Cursor — AI가 내장된 코드 에디터

내가 주로 쓰는 도구 중 하나다. VS Code 기반인데 AI 기능이 깊이 통합되어 있다. Tab 자동완성은 단순한 한 줄이 아니라 여러 줄의 맥락을 파악한 제안을 해주고, Cmd+K로 코드를 선택한 뒤 자연어로 수정 요청을 할 수 있다.

채팅 기능이 꽤 좋은데, `@파일명`으로 특정 코드를 참조하면서 대화할 수 있어서 "이 인증 로직에서 토큰 만료 처리가 제대로 되고 있는지 확인해줘"같은 질문에 실제 코드를 분석해서 답해준다.

Agent 모드가 가장 강력한데, 작업을 맡기면 프로젝트 구조 파악부터 파일 탐색, 코드 수정, 패키지 설치까지 자동으로 한다.

### Claude Code — 터미널에서 일하는 AI

Anthropic이 만든 CLI 기반 AI 코딩 에이전트다. Cursor가 "페어 프로그래밍 파트너"라면, Claude Code는 "독립적으로 일하는 팀원"에 가깝다.

```bash
$ claude
> 이 프로젝트의 구조를 파악하고 README를 업데이트해줘
```

이러면 알아서 파일 트리 탐색하고, package.json 읽고, 소스 코드 분석해서 README를 수정한다. Git 워크플로우 통합도 강력해서 커밋이나 PR 생성도 자연어로 시킬 수 있고, 멀티 파일 리팩토링("프로젝트 전체에서 moment.js를 dayjs로 교체해줘")도 잘 처리한다.

이 블로그도 Claude Code로 만들고 있는데, 포스트 작성부터 빌드 확인, 커밋까지 터미널에서 다 처리할 수 있어서 워크플로우가 꽤 매끄럽다.

### 그래서 뭘 쓸까?

코드를 보면서 수정할 때는 Cursor가 좋고, 큰 리팩토링이나 자동화 작업은 Claude Code가 낫다. 많은 개발자가 둘을 함께 쓰는데, 에디터에서는 Cursor, 터미널에서는 Claude Code — 이게 요즘 개발 워크플로우의 한 모습이다.

---

## 전체 그림

지금까지 다룬 것들을 연결해보면 이런 흐름이다.

```
LLM (GPT, Claude, Gemini...)
 │
 ├─ 프롬프트 엔지니어링 → LLM을 잘 쓰는 기술
 ├─ RAG → LLM + 외부 지식 검색
 └─ AI 에이전트 → LLM + 도구 사용 + 자율 판단
     ├─ 프레임워크: LangChain, LlamaIndex 등
     └─ 코딩 도구: Cursor, Claude Code 등
```

각 개념이 앞의 개념 위에 쌓여있다. LLM이 있으니까 자연어로 소통 가능하고, 프롬프트로 더 잘 활용하고, RAG로 지식 한계를 극복하고, 에이전트로 직접 행동하게 만들고, 프레임워크로 쉽게 제작하고, 결국 Cursor나 Claude Code로 개발자의 일상에 들어온 것이다.

---

## 어디서부터 시작할까

개발에 복귀했다면, 이론부터 파고드는 것보다 AI 코딩 도구부터 써보는 걸 추천한다. Cursor 설치하고 평소처럼 코딩하면서 AI 제안을 받아보거나, Claude Code를 터미널에서 써보면 LLM의 가능성을 직접 체감하게 된다. 거기서부터 프롬프트 엔지니어링, RAG, 에이전트 순서로 관심 가는 방향으로 깊이를 넓혀가면 된다.

개발의 본질은 변하지 않았다. 문제를 정의하고, 해결 방법을 설계하고, 코드로 구현하는 것. 다만 이제는 그 과정에서 AI라는 강력한 도구가 옆에 있을 뿐이다.

---

## 참고 자료

- [Anthropic - Claude Code](https://docs.anthropic.com/en/docs/claude-code)
- [Cursor - The AI Code Editor](https://www.cursor.com/)
- [LangChain 공식 문서](https://python.langchain.com/)
- [Anthropic - Building effective agents](https://www.anthropic.com/research/building-effective-agents)
