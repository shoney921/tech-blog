---
title: IT 회사에서 흔히 하는 RAG에 대한 오해 - 검색이 잘 될 거라는 환상을 깨다
date: 2026-02-13T13:00:00
---

# IT 회사에서 흔히 하는 RAG에 대한 오해

RAG(Retrieval-Augmented Generation)는 LLM 기반 서비스에서 가장 널리 쓰이는 아키텍처다. 하지만 실무에서 RAG를 도입할 때 **"벡터 검색이니까 의미를 완벽히 이해하겠지"**라는 기대로 시작하면 반드시 실망하게 된다. 이 글에서는 실무에서 자주 마주치는 RAG의 오해들을 하나하나 짚어본다.

---

## 오해 1: "임베딩은 의미를 완벽하게 이해한다"

### 반의어 문제 — 천국과 지옥은 벡터 공간에서 이웃이다

가장 충격적인 오해부터 시작하자. 많은 사람들이 **"의미가 반대인 단어는 벡터 공간에서도 멀리 떨어져 있을 것"**이라고 생각한다. 하지만 현실은 정반대다.

```
천국 ↔ 지옥     → 코사인 유사도: ~0.85 이상
좋다 ↔ 나쁘다   → 코사인 유사도: ~0.80 이상
성공 ↔ 실패     → 코사인 유사도: ~0.78 이상
```

**왜 이런 일이 발생하는가?**

임베딩 모델은 단어의 **분포적 의미(distributional semantics)**를 학습한다. 즉, 단어가 등장하는 **문맥(context)**이 유사하면 유사한 벡터를 갖게 된다. "천국"과 "지옥"은 종교, 사후세계, 도덕 등 **거의 동일한 문맥**에서 함께 등장하기 때문에 벡터 공간에서 매우 가깝게 위치한다.

```
"그는 천국에 갔다" vs "그는 지옥에 갔다"
→ 문장 구조와 문맥이 거의 동일
→ 임베딩 모델은 이 둘을 매우 유사하게 인코딩
```

::: danger 실무에서의 영향
고객 리뷰를 RAG로 검색할 때, "이 제품은 최고입니다"를 쿼리하면 "이 제품은 최악입니다"라는 리뷰도 높은 유사도로 함께 검색된다. **감성이 정반대인 문서가 검색 결과에 섞이는 것**이다. 이는 감성 분석, 리뷰 검색, 평판 모니터링 등의 서비스에서 치명적인 문제를 일으킨다.
:::

### 동음이의어 문제

"배"라는 단어는 문맥에 따라 과일, 신체 부위, 선박, 배수를 의미한다. 임베딩 모델은 문맥을 고려하지만, 짧은 텍스트에서는 올바른 의미를 구분하지 못하는 경우가 많다.

```
쿼리: "배가 아프다"
기대 결과: 복통 관련 의료 문서
실제 결과: 선박 사고 문서, 과일 알레르기 문서도 함께 검색
```

---

## 오해 2: "임베딩 차원이 높을수록 무조건 좋다"

### 차원의 저주 (Curse of Dimensionality)

"768차원보다 1536차원이 좋고, 3072차원은 더 좋겠지?" — 이것은 위험한 오해다.

**고차원에서 발생하는 문제들:**

1. **거리 집중 현상(Distance Concentration)**: 차원이 높아질수록 모든 벡터 간의 거리가 비슷해진다. 1000차원 이상에서는 가장 가까운 벡터와 가장 먼 벡터의 거리 차이가 극히 미미해지는 현상이 발생한다.

```
저차원 (3D):  최근접 거리 = 0.2,  최원거리 = 5.8  → 차이 명확
고차원 (3072D): 최근접 거리 = 14.1, 최원거리 = 14.9 → 차이 미미
```

2. **검색 정밀도 하락**: 거리 차이가 줄어들면 "가장 관련 있는 문서"와 "약간 관련 있는 문서"의 구분이 어려워진다. Top-K 검색 결과의 품질이 불안정해진다.

3. **연산 비용 증가**: 차원이 2배가 되면 코사인 유사도 계산 비용도 2배가 된다. 수백만 벡터를 다루는 프로덕션 환경에서는 이 차이가 인프라 비용으로 직결된다.

::: tip 실무 가이드
차원 수는 **데이터의 복잡성과 규모에 맞게** 선택해야 한다. 문서 수가 수천 건 수준이라면 768차원으로도 충분하다. 무조건 최신 고차원 모델을 쓰기보다 자신의 데이터로 실제 검색 품질을 측정하는 것이 중요하다.
:::

---

## 오해 3: "임베딩 모델은 다 비슷하다"

### 모델마다 벡터 공간이 완전히 다르다

OpenAI의 `text-embedding-3-large`와 Cohere의 `embed-v3`, Sentence-BERT 등은 모두 다른 벡터 공간을 만든다. **서로 다른 모델로 생성된 벡터는 호환되지 않는다.**

```
# 같은 문장이라도 모델이 다르면 전혀 다른 벡터
OpenAI ada-002:   [0.0023, -0.0145, 0.0312, ...]  (1536차원)
Cohere embed-v3:  [0.1245, 0.0567, -0.0891, ...]  (1024차원)
BGE-large-ko:     [-0.0432, 0.0876, 0.0234, ...]  (1024차원)

→ 이 세 벡터를 같은 벡터 DB에서 비교하면 의미 없는 결과가 나온다
```

::: danger 실무에서의 실수
프로젝트 중간에 임베딩 모델을 변경하면 **기존에 인덱싱한 모든 벡터를 재생성해야 한다.** 수백만 문서를 다시 임베딩하는 비용과 시간을 고려하지 않고 모델을 바꾸면 큰 낭패를 본다. 모델 선택은 초기에 신중하게 해야 한다.
:::

### 한국어 성능 차이

범용 영어 모델을 한국어 데이터에 그대로 적용하면 성능이 크게 떨어진다.

```
영어 모델 (text-embedding-3-large)
  "서버 장애 대응 절차" ↔ "서버 다운 시 조치 방법"
  → 유사도: ~0.72 (기대보다 낮음)

한국어 특화 모델 (KoSimCSE, BGE-m3)
  같은 쿼리 쌍
  → 유사도: ~0.89 (의미적으로 더 정확)
```

한국어는 조사, 어미 변화, 띄어쓰기 변이가 많아서 영어 중심으로 학습된 모델이 이를 제대로 포착하지 못한다.

---

## 오해 4: "청크 사이즈는 대충 정해도 된다"

### 청킹은 RAG 성능의 핵심이다

많은 팀이 "적당히 500토큰으로 자르면 되겠지"라고 생각한다. 하지만 청크 사이즈는 검색 품질에 직접적인 영향을 미친다.

**청크가 너무 작을 때:**
```
원본: "2024년 3분기 매출은 150억원으로 전년 대비 20% 증가했으며,
       영업이익률은 12%를 기록했다."

청크 1: "2024년 3분기 매출은 150억원으로"
청크 2: "전년 대비 20% 증가했으며,"
청크 3: "영업이익률은 12%를 기록했다."

→ "3분기 영업이익률은?" 쿼리 시 청크 3만 검색됨
→ 매출 맥락이 빠져서 LLM이 불완전한 답변 생성
```

**청크가 너무 클 때:**
```
2000토큰짜리 청크 안에 여러 주제가 혼재
→ 임베딩이 어떤 주제도 정확히 표현하지 못함
→ 특정 주제 검색 시 관련 없는 내용이 같이 딸려옴
→ LLM 컨텍스트를 불필요한 정보로 낭비
```

::: tip 실무 가이드
- 문서의 자연스러운 구조(단락, 섹션)를 활용한 시맨틱 청킹을 고려하라
- 청크 간 **오버랩(overlap)**을 두어 문맥 단절을 완화하라 (보통 10~20%)
- 하나의 정답은 없다 — 자신의 데이터와 질의 패턴에 맞게 실험하라
:::

---

## 오해 5: "Top-K를 늘리면 검색 품질이 좋아진다"

### 더 많이 검색한다고 더 좋은 답변이 나오지 않는다

"Top-3보다 Top-10이 나을 거고, Top-20이면 더 좋겠지?" — 이것은 LLM의 특성을 모르는 생각이다.

**문제점:**

1. **Lost in the Middle 현상**: LLM은 긴 컨텍스트의 **처음과 끝**에 있는 정보에 집중하고, **중간에 있는 정보는 무시하는 경향**이 있다. Top-20으로 검색하면 정작 가장 관련 있는 문서가 중간에 묻혀버릴 수 있다.

2. **노이즈 증가**: K값이 커질수록 관련성이 낮은 청크가 포함될 확률이 높아진다. 이 노이즈가 LLM의 응답 품질을 오히려 떨어뜨린다.

3. **토큰 비용 증가**: 더 많은 청크를 컨텍스트에 넣으면 LLM API 호출 비용이 비례해서 증가한다.

```
Top-3:  정확한 청크 3개 → LLM이 명확한 답변 생성
Top-20: 관련 청크 3개 + 노이즈 17개 → LLM이 혼란스러운 답변 생성
```

---

## 오해 6: "코사인 유사도가 높으면 관련성이 높다"

### 유사도 점수는 절대적 기준이 아니다

많은 개발자가 "코사인 유사도 0.85면 관련성이 높고, 0.5면 낮다"는 절대적 기준을 세우려 한다. 하지만 유사도 점수의 분포는 **모델, 데이터, 쿼리 유형에 따라 완전히 달라진다.**

```
모델 A: 관련 문서 유사도 평균 0.85, 비관련 문서 0.75
모델 B: 관련 문서 유사도 평균 0.65, 비관련 문서 0.30

→ 모델 A에서 0.75는 "비관련"이지만
→ 모델 B에서 0.65는 "관련"이다
```

::: warning 주의
유사도 임계값(threshold)은 모델과 데이터에 종속적이다. 하드코딩된 임계값("0.7 이상만 사용")은 모델이나 데이터가 바뀌면 무용지물이 된다. 반드시 자체 데이터셋으로 적절한 임계값을 실험적으로 결정해야 한다.
:::

---

## 오해 7: "RAG만 붙이면 할루시네이션이 사라진다"

### RAG는 할루시네이션을 줄여주지만, 없애지는 못한다

"외부 문서를 넣어주니까 LLM이 거짓말할 이유가 없지 않나?" — RAG의 가장 위험한 오해다.

**RAG에서도 할루시네이션이 발생하는 경우:**

1. **검색 실패**: 관련 문서를 못 찾으면 LLM은 자신의 학습 지식이나 추측으로 답변한다
2. **부분 일치**: 쿼리와 70%만 관련 있는 문서가 검색되면, LLM이 나머지 30%를 지어내서 답변을 완성한다
3. **컨텍스트 오독**: 검색된 문서의 내용을 LLM이 잘못 해석하거나 과도하게 일반화한다
4. **모순된 정보**: 여러 청크가 서로 모순되는 정보를 담고 있으면 LLM이 임의로 하나를 선택하거나 둘을 합성한다

```
검색된 청크: "2024년 매출은 100억원이다"
LLM 응답: "2024년 매출은 약 100억원으로, 전년 대비 15% 성장했습니다"
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
                                          검색 결과에 없는 정보를 추가
```

---

## 오해 8: "벡터 DB에 넣으면 키워드 검색보다 무조건 낫다"

### 시맨틱 검색이 키워드 검색을 완전히 대체하지 못한다

제품 코드, 법률 조항 번호, 에러 코드 같은 **정확한 텍스트 매칭이 필요한 경우** 시맨틱 검색은 키워드 검색보다 성능이 떨어진다.

```
쿼리: "ERR-5023 해결 방법"

시맨틱 검색: "에러 해결", "오류 대응" 등 의미적으로 유사한 문서를 검색
           → ERR-5023이 아니라 ERR-4011에 대한 해결법이 나올 수 있음

키워드 검색: "ERR-5023"이 정확히 포함된 문서를 검색
           → 정확한 에러 코드 문서를 찾을 확률이 높음
```

::: tip 하이브리드 검색
실무에서는 **벡터 검색 + 키워드 검색(BM25)**을 결합한 하이브리드 검색이 가장 좋은 성능을 보인다. Elasticsearch, Weaviate, Pinecone 등 대부분의 벡터 DB가 하이브리드 검색을 지원한다.

```
최종 점수 = α × 시맨틱 유사도 + (1-α) × BM25 점수
```

α값을 조절하여 시맨틱 검색과 키워드 검색의 비중을 데이터 특성에 맞게 튜닝할 수 있다.
:::

---

## 오해 9: "한 번 구축하면 유지보수가 필요 없다"

### RAG 시스템은 살아있는 시스템이다

**지속적으로 관리해야 할 항목들:**

| 항목 | 설명 | 방치 시 문제 |
|------|------|-------------|
| **문서 최신성** | 소스 문서가 업데이트되면 벡터도 갱신 | 오래된 정보로 잘못된 답변 |
| **임베딩 모델 버전** | 모델 업데이트 시 기존 벡터와 호환 불가 | 검색 품질 저하 |
| **청크 전략** | 문서 유형 변화에 따른 청킹 재설계 | 검색 누락 증가 |
| **인덱스 최적화** | 벡터 수 증가에 따른 인덱스 재구성 | 검색 속도 저하 |
| **평가 파이프라인** | 검색 및 응답 품질 모니터링 | 성능 저하를 인지하지 못함 |

---

## 오해 10: "Retrieval만 잘 되면 된다"

### Generation 단계도 똑같이 중요하다

검색 품질에만 집중하고 LLM 프롬프트 설계를 소홀히 하는 팀이 많다.

```
# 나쁜 프롬프트
"다음 문서를 참고해서 질문에 답해줘: {context}"

# 좋은 프롬프트
"아래 제공된 문서에만 기반하여 질문에 답변하세요.
문서에 답변할 수 있는 정보가 없으면 '제공된 문서에서 해당 정보를 찾을 수 없습니다'라고 답하세요.
추측하지 마세요.

문서:
{context}

질문: {query}"
```

프롬프트에서 **답변 근거를 제한**하고, **모르면 모른다고 말하라**는 지시를 명시해야 할루시네이션을 줄일 수 있다.

---

## 정리: RAG를 제대로 쓰기 위한 체크리스트

| 오해 | 현실 |
|------|------|
| 임베딩은 의미를 완벽히 이해한다 | 반의어, 동음이의어를 구분하지 못한다 |
| 차원이 높을수록 좋다 | 차원의 저주로 검색 품질이 오히려 떨어질 수 있다 |
| 임베딩 모델은 다 비슷하다 | 모델마다 벡터 공간이 완전히 달라서 호환 불가 |
| 청크 사이즈는 대충 정해도 된다 | 청킹 전략이 검색 품질의 핵심이다 |
| Top-K를 늘리면 좋아진다 | Lost in the Middle 현상으로 오히려 악화될 수 있다 |
| 코사인 유사도는 절대적이다 | 모델과 데이터에 따라 분포가 달라진다 |
| RAG = 할루시네이션 해결 | 검색 실패, 부분 매칭 시 여전히 발생한다 |
| 벡터 검색이 키워드보다 항상 낫다 | 정확한 매칭에는 키워드(BM25) 검색이 우수하다 |
| 한 번 구축하면 끝이다 | 문서, 모델, 인덱스의 지속적 관리가 필요하다 |
| Retrieval만 잘 되면 된다 | Generation 프롬프트 설계도 동일하게 중요하다 |

RAG는 강력한 도구지만, **마법이 아니다.** 벡터 검색의 한계를 이해하고, 자신의 데이터와 유스케이스에 맞게 각 파이프라인 단계를 세밀하게 튜닝해야 실무에서 기대하는 성능을 낼 수 있다.
